{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from scipy import stats\n",
    "import shutil, os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture \n",
    "import random\n",
    "from scipy import *\n",
    "from random import choice\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41050\n",
      "njnjl\n",
      "38448\n",
      "2\n",
      "aaaaaaaaa\n",
      "(2101L, 128L)\n",
      "gjgkhgkgkgkgkgg\n",
      "(2228828L, 128L)\n",
      "oooo\n",
      "2228828\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "d_list=[]\n",
    "image_paths=[]\n",
    "class_id=0\n",
    "folder=\"WordSegmentation\"\n",
    "training_names=os.listdir(folder)\n",
    "for filename in training_names: #saving the path of images in a list\n",
    "    dir = os.path.join(folder,filename)\n",
    "    image_paths.append(dir)\n",
    "    \n",
    "print(\"the no. of images in the word segmentation folder:\")\n",
    "print(len(image_paths))\n",
    "\n",
    "des_list = []\n",
    "eps=1e-7 #e=10^-7\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im=cv2.imread(image_path)\n",
    "    if im is not None and not (np.all(im==0)):\n",
    "        gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY) #converting image to gray scale\n",
    "        sift = cv2.xfeatures2d.SIFT_create() #creating a sift object\n",
    "        kp = sift.detect(gray,None) #finds the keypoint in the images\n",
    "        if (len(kp)>0):\n",
    "            kp, des = sift.compute(gray,kp) #finding descriptors from the keypoints\n",
    "            des/=(des.sum(axis=1, keepdims=True) + eps) #keepdims=True so that output isn't a vector\n",
    "            des=np.sqrt(des)\n",
    "            des_list.append((image_path, des))\n",
    "            d_list.append(des)\n",
    "            \n",
    "print(\"descriptors length and shape:\")\n",
    "print(len(d_list))\n",
    "print(len(d_list[0].shape))\n",
    "            \n",
    "sc = StandardScaler()\n",
    "\n",
    "inc=0\n",
    "reduced_list=[]\n",
    "for zz in d_list:\n",
    "    X=d_list[inc]\n",
    "    X_std = sc.fit_transform(X) #normalising the descriptors of each image\n",
    "    #print(reduced_data.shape)\n",
    "    reduced_list.append(X_std)\n",
    "    inc=inc+1\n",
    "print('aaaaaaaaa')\n",
    "print(reduced_list[0].shape)\n",
    "\n",
    "descriptors = reduced_list[0]\n",
    "\n",
    "z=[len(reduced_list[0])]\n",
    "i=0\n",
    "d=[]\n",
    "print(\"gjgkhgkgkgkgkgg\")\n",
    "\n",
    "for r in range(len(reduced_list)-1):\n",
    "    s=reduced_list[i+1]\n",
    "    z.append(len(s))\n",
    "    if s is not None:\n",
    "        d.append(reduced_list[i+1])\n",
    "        descriptors = np.vstack((descriptors,s))\n",
    "    i=i+1\n",
    "    \n",
    "import csv\n",
    "with open('finala.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(descriptors)\n",
    "csvFile.close()\n",
    "\n",
    "print(descriptors.shape)\n",
    "print('oooo')\n",
    "print(sum(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "clustering = MiniBatchKMeans(n_clusters = 8000, init = 'k-means++', batch_size=8000, random_state = 42, n_init=30)\n",
    "model = clustering.fit_predict(descriptors)\n",
    "print(\"kkkk\") \n",
    "n=0\n",
    "t=[]\n",
    "for a in z:\n",
    "    #print(des_list[n][0])\n",
    "    rr=stats.mode(model[m:m+a])[0][0]\n",
    "    #print(rr)\n",
    "    m=m+a\n",
    "    \n",
    "    if(rr in t):\n",
    "        dest_folder1=\"finalkmeansclass/\"+str(rr)\n",
    "        shutil.copy(des_list[n][0], dest_folder1)      \n",
    "    else:\n",
    "        t.append(rr)\n",
    "        dest_folder=\"finalkmeansclass/\"+str(rr)\n",
    "        os.mkdir(dest_folder)\n",
    "        shutil.copy(des_list[n][0], dest_folder)\n",
    "    n=n+1\n",
    "print(m)\n",
    "print(descriptors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
